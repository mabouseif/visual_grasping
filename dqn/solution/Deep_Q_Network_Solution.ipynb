{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Network (DQN)\n",
    "---\n",
    "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Environment and Agent\n",
    "\n",
    "Initialize the environment in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed/Downloads/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the instructions in `Deep_Q_Network.ipynb` if you would like to write your own DQN agent.  Otherwise, run the code cell below to load the solution files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "\n",
    "# watch an untrained agent\n",
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    action = agent.act(state)\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with DQN\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  You are welcome to amend the supplied values of the parameters in the function, to try to see if you can get better performance!\n",
    "\n",
    "Alternatively, you can skip to the next step below (**4. Watch a Smart Agent!**), to load the saved model weights from a pre-trained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -168.32\n",
      "Episode 200\tAverage Score: -101.62\n",
      "Episode 300\tAverage Score: -35.678\n",
      "Episode 400\tAverage Score: -2.799\n",
      "Episode 500\tAverage Score: 96.78\n",
      "Episode 600\tAverage Score: 188.79\n",
      "Episode 617\tAverage Score: 200.29\n",
      "Environment solved in 517 episodes!\tAverage Score: 200.29\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "for i in range(3):\n",
    "    state = env.reset()\n",
    "    for j in range(500):\n",
    "        action = agent.act(state)\n",
    "        env.render()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            print(reward)\n",
    "            break \n",
    "        time.sleep(0.01)\n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Explore\n",
    "\n",
    "In this exercise, you have implemented a DQN agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
    "- Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster.  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task with discrete actions!\n",
    "- You may like to implement some improvements such as prioritized experience replay, Double DQN, or Dueling DQN! \n",
    "- Write a blog post explaining the intuition behind the DQN algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import cv2\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from robot import Robot\n",
    "from trainer import Trainer\n",
    "from logger import Logger\n",
    "import utils\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "\n",
    "    # --------------- Setup options ---------------\n",
    "    is_sim = args.is_sim # Run in simulation?\n",
    "    obj_mesh_dir = os.path.abspath(args.obj_mesh_dir) if is_sim else None # Directory containing 3D mesh files (.obj) of objects to be added to simulation\n",
    "    num_obj = args.num_obj if is_sim else None # Number of objects to add to simulation\n",
    "    tcp_host_ip = args.tcp_host_ip if not is_sim else None # IP and port to robot arm as TCP client (UR5)\n",
    "    tcp_port = args.tcp_port if not is_sim else None\n",
    "    rtc_host_ip = args.rtc_host_ip if not is_sim else None # IP and port to robot arm as real-time client (UR5)\n",
    "    rtc_port = args.rtc_port if not is_sim else None\n",
    "    if is_sim:\n",
    "        workspace_limits = np.asarray([[-0.724, -0.276], [-0.224, 0.224], [-0.0001, 0.4]]) # Cols: min max, Rows: x y z (define workspace limits in robot coordinates)\n",
    "    else:\n",
    "        workspace_limits = np.asarray([[0.3, 0.748], [-0.224, 0.224], [-0.255, -0.1]]) # Cols: min max, Rows: x y z (define workspace limits in robot coordinates)\n",
    "    heightmap_resolution = args.heightmap_resolution # Meters per pixel of heightmap\n",
    "    random_seed = args.random_seed\n",
    "    force_cpu = args.force_cpu\n",
    "\n",
    "    # ------------- Algorithm options -------------\n",
    "    method = args.method # 'reactive' (supervised learning) or 'reinforcement' (reinforcement learning ie Q-learning)\n",
    "    push_rewards = args.push_rewards if method == 'reinforcement' else None  # Use immediate rewards (from change detection) for pushing?\n",
    "    future_reward_discount = args.future_reward_discount\n",
    "    experience_replay = args.experience_replay # Use prioritized experience replay?\n",
    "    heuristic_bootstrap = args.heuristic_bootstrap # Use handcrafted grasping algorithm when grasping fails too many times in a row?\n",
    "    explore_rate_decay = args.explore_rate_decay\n",
    "    grasp_only = args.grasp_only\n",
    "\n",
    "    # -------------- Testing options --------------\n",
    "    is_testing = args.is_testing\n",
    "    max_test_trials = args.max_test_trials # Maximum number of test runs per case/scenario\n",
    "    test_preset_cases = args.test_preset_cases\n",
    "    test_preset_file = os.path.abspath(args.test_preset_file) if test_preset_cases else None\n",
    "\n",
    "    # ------ Pre-loading and logging options ------\n",
    "    load_snapshot = args.load_snapshot # Load pre-trained snapshot of model?\n",
    "    snapshot_file = os.path.abspath(args.snapshot_file)  if load_snapshot else None\n",
    "    continue_logging = args.continue_logging # Continue logging from previous session\n",
    "    logging_directory = os.path.abspath(args.logging_directory) if continue_logging else os.path.abspath('logs')\n",
    "    save_visualizations = args.save_visualizations # Save visualizations of FCN predictions? Takes 0.6s per training step if set to True\n",
    "\n",
    "\n",
    "    # Set random seed\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Initialize pick-and-place system (camera and robot)\n",
    "    robot = Robot(is_sim, obj_mesh_dir, num_obj, workspace_limits,\n",
    "                  tcp_host_ip, tcp_port, rtc_host_ip, rtc_port,\n",
    "                  is_testing, test_preset_cases, test_preset_file)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(method, push_rewards, future_reward_discount,\n",
    "                      is_testing, load_snapshot, snapshot_file, force_cpu)\n",
    "\n",
    "    # Initialize data logger\n",
    "    logger = Logger(continue_logging, logging_directory)\n",
    "    logger.save_camera_info(robot.cam_intrinsics, robot.cam_pose, robot.cam_depth_scale) # Save camera intrinsics and pose\n",
    "    logger.save_heightmap_info(workspace_limits, heightmap_resolution) # Save heightmap parameters\n",
    "\n",
    "    # Find last executed iteration of pre-loaded log, and load execution info and RL variables\n",
    "    if continue_logging:\n",
    "        trainer.preload(logger.transitions_directory)\n",
    "\n",
    "    # Initialize variables for heuristic bootstrapping and exploration probability\n",
    "    no_change_count = [2, 2] if not is_testing else [0, 0]\n",
    "    explore_prob = 0.5 if not is_testing else 0.0\n",
    "\n",
    "    # Quick hack for nonlocal memory between threads in Python 2\n",
    "    nonlocal_variables = {'executing_action' : False,\n",
    "                          'primitive_action' : None,\n",
    "                          'best_pix_ind' : None,\n",
    "                          'push_success' : False,\n",
    "                          'grasp_success' : False}\n",
    "\n",
    "\n",
    "    # Parallel thread to process network output and execute actions\n",
    "    # -------------------------------------------------------------\n",
    "    def process_actions():\n",
    "        while True:\n",
    "            if nonlocal_variables['executing_action']:\n",
    "\n",
    "                # Determine whether grasping or pushing should be executed based on network predictions\n",
    "                best_push_conf = np.max(push_predictions)\n",
    "                best_grasp_conf = np.max(grasp_predictions)\n",
    "                print('Primitive confidence scores: %f (push), %f (grasp)' % (best_push_conf, best_grasp_conf))\n",
    "                nonlocal_variables['primitive_action'] = 'grasp'\n",
    "                explore_actions = False\n",
    "                if not grasp_only:\n",
    "                    if is_testing and method == 'reactive':\n",
    "                        if best_push_conf > 2*best_grasp_conf:\n",
    "                            nonlocal_variables['primitive_action'] = 'push'\n",
    "                    else:\n",
    "                        if best_push_conf > best_grasp_conf:\n",
    "                            nonlocal_variables['primitive_action'] = 'push'\n",
    "                    explore_actions = np.random.uniform() < explore_prob\n",
    "                    if explore_actions: # Exploitation (do best action) vs exploration (do other action)\n",
    "                        print('Strategy: explore (exploration probability: %f)' % (explore_prob))\n",
    "                        nonlocal_variables['primitive_action'] = 'push' if np.random.randint(0,2) == 0 else 'grasp'\n",
    "                    else:\n",
    "                        print('Strategy: exploit (exploration probability: %f)' % (explore_prob))\n",
    "                trainer.is_exploit_log.append([0 if explore_actions else 1])\n",
    "                logger.write_to_log('is-exploit', trainer.is_exploit_log)\n",
    "\n",
    "                # If heuristic bootstrapping is enabled: if change has not been detected more than 2 times, execute heuristic algorithm to detect grasps/pushes\n",
    "                # NOTE: typically not necessary and can reduce final performance.\n",
    "                if heuristic_bootstrap and nonlocal_variables['primitive_action'] == 'push' and no_change_count[0] >= 2:\n",
    "                    print('Change not detected for more than two pushes. Running heuristic pushing.')\n",
    "                    nonlocal_variables['best_pix_ind'] = trainer.push_heuristic(valid_depth_heightmap)\n",
    "                    no_change_count[0] = 0\n",
    "                    predicted_value = push_predictions[nonlocal_variables['best_pix_ind']]\n",
    "                    use_heuristic = True\n",
    "                elif heuristic_bootstrap and nonlocal_variables['primitive_action'] == 'grasp' and no_change_count[1] >= 2:\n",
    "                    print('Change not detected for more than two grasps. Running heuristic grasping.')\n",
    "                    nonlocal_variables['best_pix_ind'] = trainer.grasp_heuristic(valid_depth_heightmap)\n",
    "                    no_change_count[1] = 0\n",
    "                    predicted_value = grasp_predictions[nonlocal_variables['best_pix_ind']]\n",
    "                    use_heuristic = True\n",
    "                else:\n",
    "                    use_heuristic = False\n",
    "\n",
    "                    # Get pixel location and rotation with highest affordance prediction from heuristic algorithms (rotation, y, x)\n",
    "                    if nonlocal_variables['primitive_action'] == 'push':\n",
    "                        nonlocal_variables['best_pix_ind'] = np.unravel_index(np.argmax(push_predictions), push_predictions.shape)\n",
    "                        predicted_value = np.max(push_predictions)\n",
    "                    elif nonlocal_variables['primitive_action'] == 'grasp':\n",
    "                        nonlocal_variables['best_pix_ind'] = np.unravel_index(np.argmax(grasp_predictions), grasp_predictions.shape)\n",
    "                        predicted_value = np.max(grasp_predictions)\n",
    "                trainer.use_heuristic_log.append([1 if use_heuristic else 0])\n",
    "                logger.write_to_log('use-heuristic', trainer.use_heuristic_log)\n",
    "\n",
    "                # Save predicted confidence value\n",
    "                trainer.predicted_value_log.append([predicted_value])\n",
    "                logger.write_to_log('predicted-value', trainer.predicted_value_log)\n",
    "\n",
    "                # Compute 3D position of pixel\n",
    "                print('Action: %s at (%d, %d, %d)' % (nonlocal_variables['primitive_action'], nonlocal_variables['best_pix_ind'][0], nonlocal_variables['best_pix_ind'][1], nonlocal_variables['best_pix_ind'][2]))\n",
    "                best_rotation_angle = np.deg2rad(nonlocal_variables['best_pix_ind'][0]*(360.0/trainer.model.num_rotations))\n",
    "                best_pix_x = nonlocal_variables['best_pix_ind'][2]\n",
    "                best_pix_y = nonlocal_variables['best_pix_ind'][1]\n",
    "                primitive_position = [best_pix_x * heightmap_resolution + workspace_limits[0][0], best_pix_y * heightmap_resolution + workspace_limits[1][0], valid_depth_heightmap[best_pix_y][best_pix_x] + workspace_limits[2][0]]\n",
    "\n",
    "                # If pushing, adjust start position, and make sure z value is safe and not too low\n",
    "                if nonlocal_variables['primitive_action'] == 'push': # or nonlocal_variables['primitive_action'] == 'place':\n",
    "                    finger_width = 0.02\n",
    "                    safe_kernel_width = int(np.round((finger_width/2)/heightmap_resolution))\n",
    "                    local_region = valid_depth_heightmap[max(best_pix_y - safe_kernel_width, 0):min(best_pix_y + safe_kernel_width + 1, valid_depth_heightmap.shape[0]), max(best_pix_x - safe_kernel_width, 0):min(best_pix_x + safe_kernel_width + 1, valid_depth_heightmap.shape[1])]\n",
    "                    if local_region.size == 0:\n",
    "                        safe_z_position = workspace_limits[2][0]\n",
    "                    else:\n",
    "                        safe_z_position = np.max(local_region) + workspace_limits[2][0]\n",
    "                    primitive_position[2] = safe_z_position\n",
    "\n",
    "                # Save executed primitive\n",
    "                if nonlocal_variables['primitive_action'] == 'push':\n",
    "                    trainer.executed_action_log.append([0, nonlocal_variables['best_pix_ind'][0], nonlocal_variables['best_pix_ind'][1], nonlocal_variables['best_pix_ind'][2]]) # 0 - push\n",
    "                elif nonlocal_variables['primitive_action'] == 'grasp':\n",
    "                    trainer.executed_action_log.append([1, nonlocal_variables['best_pix_ind'][0], nonlocal_variables['best_pix_ind'][1], nonlocal_variables['best_pix_ind'][2]]) # 1 - grasp\n",
    "                logger.write_to_log('executed-action', trainer.executed_action_log)\n",
    "\n",
    "                # Visualize executed primitive, and affordances\n",
    "                if save_visualizations:\n",
    "                    push_pred_vis = trainer.get_prediction_vis(push_predictions, color_heightmap, nonlocal_variables['best_pix_ind'])\n",
    "                    logger.save_visualizations(trainer.iteration, push_pred_vis, 'push')\n",
    "                    cv2.imwrite('visualization.push.png', push_pred_vis)\n",
    "                    grasp_pred_vis = trainer.get_prediction_vis(grasp_predictions, color_heightmap, nonlocal_variables['best_pix_ind'])\n",
    "                    logger.save_visualizations(trainer.iteration, grasp_pred_vis, 'grasp')\n",
    "                    cv2.imwrite('visualization.grasp.png', grasp_pred_vis)\n",
    "\n",
    "                # Initialize variables that influence reward\n",
    "                nonlocal_variables['push_success'] = False\n",
    "                nonlocal_variables['grasp_success'] = False\n",
    "                change_detected = False\n",
    "\n",
    "                # Execute primitive\n",
    "                if nonlocal_variables['primitive_action'] == 'push':\n",
    "                    nonlocal_variables['push_success'] = robot.push(primitive_position, best_rotation_angle, workspace_limits)\n",
    "                    print('Push successful: %r' % (nonlocal_variables['push_success']))\n",
    "                elif nonlocal_variables['primitive_action'] == 'grasp':\n",
    "                    nonlocal_variables['grasp_success'] = robot.grasp(primitive_position, best_rotation_angle, workspace_limits)\n",
    "                    print('Grasp successful: %r' % (nonlocal_variables['grasp_success']))\n",
    "\n",
    "                nonlocal_variables['executing_action'] = False\n",
    "\n",
    "            time.sleep(0.01)\n",
    "    action_thread = threading.Thread(target=process_actions)\n",
    "    action_thread.daemon = True\n",
    "    action_thread.start()\n",
    "    exit_called = False\n",
    "    # -------------------------------------------------------------\n",
    "    # -------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # Start main training/testing loop\n",
    "    while True:\n",
    "        print('\\n%s iteration: %d' % ('Testing' if is_testing else 'Training', trainer.iteration))\n",
    "        iteration_time_0 = time.time()\n",
    "\n",
    "        # Get latest RGB-D image\n",
    "        color_img, depth_img = robot.get_camera_data()\n",
    "        depth_img = depth_img * robot.cam_depth_scale # Apply depth scale from calibration\n",
    "\n",
    "        # Get heightmap from RGB-D image (by re-projecting 3D point cloud)\n",
    "        color_heightmap, depth_heightmap = utils.get_heightmap(color_img, depth_img, robot.cam_intrinsics, robot.cam_pose, workspace_limits, heightmap_resolution)\n",
    "        valid_depth_heightmap = depth_heightmap.copy()\n",
    "        valid_depth_heightmap[np.isnan(valid_depth_heightmap)] = 0\n",
    "\n",
    "        # Save RGB-D images and RGB-D heightmaps\n",
    "        logger.save_images(trainer.iteration, color_img, depth_img, '0')\n",
    "        logger.save_heightmaps(trainer.iteration, color_heightmap, valid_depth_heightmap, '0')\n",
    "\n",
    "        # Run forward pass with network to get affordances\n",
    "        push_predictions, grasp_predictions, state_feat = trainer.forward(color_heightmap, valid_depth_heightmap, is_volatile=True)\n",
    "\n",
    "        # Execute best primitive action on robot in another thread\n",
    "        nonlocal_variables['executing_action'] = True\n",
    "        \n",
    "        # Determine whether grasping or pushing should be executed based on network predictions\n",
    "        best_grasp_conf = np.max(grasp_predictions)\n",
    "        print('Primitive confidence scores: %f (grasp)' % (best_grasp_conf))\n",
    "        nonlocal_variables['primitive_action'] = 'grasp'\n",
    "        explore_actions = False\n",
    "        trainer.is_exploit_log.append([0 if explore_actions else 1])\n",
    "        logger.write_to_log('is-exploit', trainer.is_exploit_log)\n",
    "\n",
    "\n",
    "        use_heuristic = False\n",
    "            \n",
    "        nonlocal_variables['best_pix_ind'] = np.unravel_index(np.argmax(grasp_predictions), grasp_predictions.shape)\n",
    "        predicted_value = np.max(grasp_predictions)\n",
    "        trainer.use_heuristic_log.append([1 if use_heuristic else 0])\n",
    "        logger.write_to_log('use-heuristic', trainer.use_heuristic_log)\n",
    "\n",
    "        # Save predicted confidence value\n",
    "        trainer.predicted_value_log.append([predicted_value])\n",
    "        logger.write_to_log('predicted-value', trainer.predicted_value_log)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Compute 3D position of pixel\n",
    "        print('Action: %s at (%d, %d, %d)' % (nonlocal_variables['primitive_action'], nonlocal_variables['best_pix_ind'][0], nonlocal_variables['best_pix_ind'][1], nonlocal_variables['best_pix_ind'][2]))\n",
    "        best_rotation_angle = np.deg2rad(nonlocal_variables['best_pix_ind'][0]*(360.0/trainer.model.num_rotations))\n",
    "        best_pix_x = nonlocal_variables['best_pix_ind'][2]\n",
    "        best_pix_y = nonlocal_variables['best_pix_ind'][1]\n",
    "        primitive_position = [best_pix_x * heightmap_resolution + workspace_limits[0][0], best_pix_y * heightmap_resolution + workspace_limits[1][0], valid_depth_heightmap[best_pix_y][best_pix_x] + workspace_limits[2][0]]\n",
    "\n",
    "         # Save executed primitive\n",
    "        trainer.executed_action_log.append([1, nonlocal_variables['best_pix_ind'][0], nonlocal_variables['best_pix_ind'][1], nonlocal_variables['best_pix_ind'][2]]) # 1 - grasp\n",
    "        logger.write_to_log('executed-action', trainer.executed_action_log)\n",
    "\n",
    "\n",
    "        # Visualize executed primitive, and affordances\n",
    "        if save_visualizations:\n",
    "            grasp_pred_vis = trainer.get_prediction_vis(grasp_predictions, color_heightmap, nonlocal_variables['best_pix_ind'])\n",
    "            logger.save_visualizations(trainer.iteration, grasp_pred_vis, 'grasp')\n",
    "            cv2.imwrite('visualization.grasp.png', grasp_pred_vis)\n",
    "\n",
    "        # Initialize variables that influence reward\n",
    "        nonlocal_variables['grasp_success'] = False\n",
    "        change_detected = False\n",
    "\n",
    "        # Execute primitive\n",
    "        nonlocal_variables['grasp_success'] = robot.grasp(primitive_position, best_rotation_angle, workspace_limits)\n",
    "        print('Grasp successful: %r' % (nonlocal_variables['grasp_success']))\n",
    "\n",
    "        nonlocal_variables['executing_action'] = False\n",
    "\n",
    "\n",
    "#         time.sleep(0.01)\n",
    "#         action_thread = threading.Thread(target=process_actions)\n",
    "#         action_thread.daemon = True\n",
    "#         action_thread.start()\n",
    "#         exit_called = False        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # Run training iteration in current thread (aka training thread)\n",
    "        if 'prev_color_img' in locals():\n",
    "\n",
    "            # Detect changes\n",
    "            depth_diff = abs(depth_heightmap - prev_depth_heightmap)\n",
    "            depth_diff[np.isnan(depth_diff)] = 0\n",
    "            depth_diff[depth_diff > 0.3] = 0\n",
    "            depth_diff[depth_diff < 0.01] = 0\n",
    "            depth_diff[depth_diff > 0] = 1\n",
    "            change_threshold = 300\n",
    "            change_value = np.sum(depth_diff)\n",
    "            change_detected = change_value > change_threshold or prev_grasp_success\n",
    "            print('Change detected: %r (value: %d)' % (change_detected, change_value))\n",
    "\n",
    "            if change_detected:\n",
    "                if prev_primitive_action == 'push':\n",
    "                    no_change_count[0] = 0\n",
    "                elif prev_primitive_action == 'grasp':\n",
    "                    no_change_count[1] = 0\n",
    "            else:\n",
    "                if prev_primitive_action == 'push':\n",
    "                    no_change_count[0] += 1\n",
    "                elif prev_primitive_action == 'grasp':\n",
    "                    no_change_count[1] += 1\n",
    "\n",
    "            # Compute training labels\n",
    "            label_value, prev_reward_value = trainer.get_label_value(prev_primitive_action, prev_push_success, prev_grasp_success, change_detected, prev_push_predictions, prev_grasp_predictions, color_heightmap, valid_depth_heightmap)\n",
    "            trainer.label_value_log.append([label_value])\n",
    "            logger.write_to_log('label-value', trainer.label_value_log)\n",
    "            trainer.reward_value_log.append([prev_reward_value])\n",
    "            logger.write_to_log('reward-value', trainer.reward_value_log)\n",
    "\n",
    "            # Backpropagate\n",
    "            trainer.backprop(prev_color_heightmap, prev_valid_depth_heightmap, prev_primitive_action, prev_best_pix_ind, label_value)\n",
    "\n",
    "            # Adjust exploration probability\n",
    "            if not is_testing:\n",
    "                explore_prob = max(0.5 * np.power(0.9998, trainer.iteration),0.1) if explore_rate_decay else 0.5\n",
    "\n",
    "            # Do sampling for experience replay\n",
    "            if experience_replay and not is_testing:\n",
    "                sample_primitive_action = prev_primitive_action\n",
    "                if sample_primitive_action == 'push':\n",
    "                    sample_primitive_action_id = 0\n",
    "                    if method == 'reactive':\n",
    "                        sample_reward_value = 0 if prev_reward_value == 1 else 1 # random.randint(1, 2) # 2\n",
    "                    elif method == 'reinforcement':\n",
    "                        sample_reward_value = 0 if prev_reward_value == 0.5 else 0.5\n",
    "                elif sample_primitive_action == 'grasp':\n",
    "                    sample_primitive_action_id = 1\n",
    "                    if method == 'reactive':\n",
    "                        sample_reward_value = 0 if prev_reward_value == 1 else 1\n",
    "                    elif method == 'reinforcement':\n",
    "                        sample_reward_value = 0 if prev_reward_value == 1 else 1\n",
    "\n",
    "                # Get samples of the same primitive but with different results\n",
    "                sample_ind = np.argwhere(np.logical_and(np.asarray(trainer.reward_value_log)[1:trainer.iteration,0] == sample_reward_value, np.asarray(trainer.executed_action_log)[1:trainer.iteration,0] == sample_primitive_action_id))\n",
    "\n",
    "                if sample_ind.size > 0:\n",
    "\n",
    "                    # Find sample with highest surprise value\n",
    "                    if method == 'reactive':\n",
    "                        sample_surprise_values = np.abs(np.asarray(trainer.predicted_value_log)[sample_ind[:,0]] - (1 - sample_reward_value))\n",
    "                    elif method == 'reinforcement':\n",
    "                        sample_surprise_values = np.abs(np.asarray(trainer.predicted_value_log)[sample_ind[:,0]] - np.asarray(trainer.label_value_log)[sample_ind[:,0]])\n",
    "                    sorted_surprise_ind = np.argsort(sample_surprise_values[:,0])\n",
    "                    sorted_sample_ind = sample_ind[sorted_surprise_ind,0]\n",
    "                    pow_law_exp = 2\n",
    "                    rand_sample_ind = int(np.round(np.random.power(pow_law_exp, 1)*(sample_ind.size-1)))\n",
    "                    sample_iteration = sorted_sample_ind[rand_sample_ind]\n",
    "                    print('Experience replay: iteration %d (surprise value: %f)' % (sample_iteration, sample_surprise_values[sorted_surprise_ind[rand_sample_ind]]))\n",
    "\n",
    "                    # Load sample RGB-D heightmap\n",
    "                    sample_color_heightmap = cv2.imread(os.path.join(logger.color_heightmaps_directory, '%06d.0.color.png' % (sample_iteration)))\n",
    "                    sample_color_heightmap = cv2.cvtColor(sample_color_heightmap, cv2.COLOR_BGR2RGB)\n",
    "                    sample_depth_heightmap = cv2.imread(os.path.join(logger.depth_heightmaps_directory, '%06d.0.depth.png' % (sample_iteration)), -1)\n",
    "                    sample_depth_heightmap = sample_depth_heightmap.astype(np.float32)/100000\n",
    "\n",
    "                    # Compute forward pass with sample\n",
    "                    with torch.no_grad():\n",
    "                        sample_push_predictions, sample_grasp_predictions, sample_state_feat = trainer.forward(sample_color_heightmap, sample_depth_heightmap, is_volatile=True)\n",
    "\n",
    "                    # Load next sample RGB-D heightmap\n",
    "                    next_sample_color_heightmap = cv2.imread(os.path.join(logger.color_heightmaps_directory, '%06d.0.color.png' % (sample_iteration+1)))\n",
    "                    next_sample_color_heightmap = cv2.cvtColor(next_sample_color_heightmap, cv2.COLOR_BGR2RGB)\n",
    "                    next_sample_depth_heightmap = cv2.imread(os.path.join(logger.depth_heightmaps_directory, '%06d.0.depth.png' % (sample_iteration+1)), -1)\n",
    "                    next_sample_depth_heightmap = next_sample_depth_heightmap.astype(np.float32)/100000\n",
    "\n",
    "                    sample_push_success = sample_reward_value == 0.5\n",
    "                    sample_grasp_success = sample_reward_value == 1\n",
    "                    sample_change_detected = sample_push_success\n",
    "                    # new_sample_label_value, _ = trainer.get_label_value(sample_primitive_action, sample_push_success, sample_grasp_success, sample_change_detected, sample_push_predictions, sample_grasp_predictions, next_sample_color_heightmap, next_sample_depth_heightmap)\n",
    "\n",
    "                    # Get labels for sample and backpropagate\n",
    "                    sample_best_pix_ind = (np.asarray(trainer.executed_action_log)[sample_iteration,1:4]).astype(int)\n",
    "                    trainer.backprop(sample_color_heightmap, sample_depth_heightmap, sample_primitive_action, sample_best_pix_ind, trainer.label_value_log[sample_iteration])\n",
    "\n",
    "                    # Recompute prediction value and label for replay buffer\n",
    "                    if sample_primitive_action == 'push':\n",
    "                        trainer.predicted_value_log[sample_iteration] = [np.max(sample_push_predictions)]\n",
    "                        # trainer.label_value_log[sample_iteration] = [new_sample_label_value]\n",
    "                    elif sample_primitive_action == 'grasp':\n",
    "                        trainer.predicted_value_log[sample_iteration] = [np.max(sample_grasp_predictions)]\n",
    "                        # trainer.label_value_log[sample_iteration] = [new_sample_label_value]\n",
    "\n",
    "                else:\n",
    "                    print('Not enough prior training samples. Skipping experience replay.')\n",
    "\n",
    "            # Save model snapshot\n",
    "            if not is_testing:\n",
    "                logger.save_backup_model(trainer.model, method)\n",
    "                if trainer.iteration % 50 == 0:\n",
    "                    logger.save_model(trainer.iteration, trainer.model, method)\n",
    "                    if trainer.use_cuda:\n",
    "                        trainer.model = trainer.model.cuda()\n",
    "\n",
    "        # Sync both action thread and training thread\n",
    "        while nonlocal_variables['executing_action']:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        if exit_called:\n",
    "            break\n",
    "\n",
    "        # Save information for next training step\n",
    "        prev_color_img = color_img.copy()\n",
    "        prev_depth_img = depth_img.copy()\n",
    "        prev_color_heightmap = color_heightmap.copy()\n",
    "        prev_depth_heightmap = depth_heightmap.copy()\n",
    "        prev_valid_depth_heightmap = valid_depth_heightmap.copy()\n",
    "        prev_push_success = nonlocal_variables['push_success']\n",
    "        prev_grasp_success = nonlocal_variables['grasp_success']\n",
    "        prev_primitive_action = nonlocal_variables['primitive_action']\n",
    "        prev_push_predictions = push_predictions.copy()\n",
    "        prev_grasp_predictions = grasp_predictions.copy()\n",
    "        prev_best_pix_ind = nonlocal_variables['best_pix_ind']\n",
    "\n",
    "        trainer.iteration += 1\n",
    "        iteration_time_1 = time.time()\n",
    "        print('Time elapsed: %f' % (iteration_time_1-iteration_time_0))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Parse arguments\n",
    "    parser = argparse.ArgumentParser(description='Train robotic agents to learn how to plan complementary pushing and grasping actions for manipulation with deep reinforcement learning in PyTorch.')\n",
    "\n",
    "    # --------------- Setup options ---------------\n",
    "    parser.add_argument('--is_sim', dest='is_sim', action='store_true', default=False,                                    help='run in simulation?')\n",
    "    parser.add_argument('--obj_mesh_dir', dest='obj_mesh_dir', action='store', default='objects/blocks',                  help='directory containing 3D mesh files (.obj) of objects to be added to simulation')\n",
    "    parser.add_argument('--num_obj', dest='num_obj', type=int, action='store', default=10,                                help='number of objects to add to simulation')\n",
    "    parser.add_argument('--tcp_host_ip', dest='tcp_host_ip', action='store', default='100.127.7.223',                     help='IP address to robot arm as TCP client (UR5)')\n",
    "    parser.add_argument('--tcp_port', dest='tcp_port', type=int, action='store', default=30002,                           help='port to robot arm as TCP client (UR5)')\n",
    "    parser.add_argument('--rtc_host_ip', dest='rtc_host_ip', action='store', default='100.127.7.223',                     help='IP address to robot arm as real-time client (UR5)')\n",
    "    parser.add_argument('--rtc_port', dest='rtc_port', type=int, action='store', default=30003,                           help='port to robot arm as real-time client (UR5)')\n",
    "    parser.add_argument('--heightmap_resolution', dest='heightmap_resolution', type=float, action='store', default=0.002, help='meters per pixel of heightmap')\n",
    "    parser.add_argument('--random_seed', dest='random_seed', type=int, action='store', default=1234,                      help='random seed for simulation and neural net initialization')\n",
    "    parser.add_argument('--cpu', dest='force_cpu', action='store_true', default=False,                                    help='force code to run in CPU mode')\n",
    "\n",
    "    # ------------- Algorithm options -------------\n",
    "    parser.add_argument('--method', dest='method', action='store', default='reinforcement',                               help='set to \\'reactive\\' (supervised learning) or \\'reinforcement\\' (reinforcement learning ie Q-learning)')\n",
    "    parser.add_argument('--push_rewards', dest='push_rewards', action='store_true', default=False,                        help='use immediate rewards (from change detection) for pushing?')\n",
    "    parser.add_argument('--future_reward_discount', dest='future_reward_discount', type=float, action='store', default=0.5)\n",
    "    parser.add_argument('--experience_replay', dest='experience_replay', action='store_true', default=False,              help='use prioritized experience replay?')\n",
    "    parser.add_argument('--heuristic_bootstrap', dest='heuristic_bootstrap', action='store_true', default=False,          help='use handcrafted grasping algorithm when grasping fails too many times in a row during training?')\n",
    "    parser.add_argument('--explore_rate_decay', dest='explore_rate_decay', action='store_true', default=False)\n",
    "    parser.add_argument('--grasp_only', dest='grasp_only', action='store_true', default=False)\n",
    "\n",
    "    # -------------- Testing options --------------\n",
    "    parser.add_argument('--is_testing', dest='is_testing', action='store_true', default=False)\n",
    "    parser.add_argument('--max_test_trials', dest='max_test_trials', type=int, action='store', default=30,                help='maximum number of test runs per case/scenario')\n",
    "    parser.add_argument('--test_preset_cases', dest='test_preset_cases', action='store_true', default=False)\n",
    "    parser.add_argument('--test_preset_file', dest='test_preset_file', action='store', default='test-10-obj-01.txt')\n",
    "\n",
    "    # ------ Pre-loading and logging options ------\n",
    "    parser.add_argument('--load_snapshot', dest='load_snapshot', action='store_true', default=False,                      help='load pre-trained snapshot of model?')\n",
    "    parser.add_argument('--snapshot_file', dest='snapshot_file', action='store')\n",
    "    parser.add_argument('--continue_logging', dest='continue_logging', action='store_true', default=False,                help='continue logging from previous session?')\n",
    "    parser.add_argument('--logging_directory', dest='logging_directory', action='store')\n",
    "    parser.add_argument('--save_visualizations', dest='save_visualizations', action='store_true', default=False,          help='save visualizations of FCN predictions?')\n",
    "\n",
    "    # Run main program with specified arguments\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
